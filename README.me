Deploying a checksum:

Step 1: Deploy a master database connector.
If you already have a connector setup for this database connection, skip this step.

Create a new bot and use this for the index.js:
// use the connector for your database type:
const connector = require('leo-connector-(sqlserver|postgres|mysql)');

module.exports = connector.checksum({
	host: process.env.DB_HOST, // use server instead of host when using sqlserver. 
	user: process.env.DB_USER,
	port: process.env.DB_PORT,
	database: process.env.DB_NAME,
	password: process.env.KMS_DB_PASSWORD
});

Use this for the package.json, replace mysql with your connector type:
{
	"name": “mysqlConnector",
	"version": "1.0.0",
	"description": “MySQL connector",
	"main": "index.js",
	"directories": {
		"test": "test"
	},
	"scripts": {
		"test": "leo-cli test . "
	},
	"config": {
		"leo": {
		"type": "bot",
			"memory": 256,
			"timeout": 300,
			"role": "ApiRole"
		}
	}
}

If you use a VPC to connect to your database, put the VpcConfig here as well.

Step 2: Deploy a slave database connector. This will be your data warehouse.
Repeat step 1 for this bot but with your data warehouse connection database information.
See additional notes for going to an API endpoint instead of a database.

Step 3: Deploy both connector bots.

Step 4: Go to AWS Lambda and search for the name of your bot. The name in Lambda should look something like this:
Leo-MySQLConnector-7V30933JF9JF3. Copy the full name from both connectors. You’ll need that in the following steps.

Step 5: Create a checksum bot, and make the following changes to the package.json file:
Inside config.leo, add the 2 connectors to your config.leo.env. Example: 

"config": {
	"leo": {
		"type": "cron",
		"memory": 256,
		"timeout": 300,
		"role": "ApiRole",
		"env": {
			“master_lambda": {
				"Fn::Sub": “${mysqlConnector}"
			},
			“slave_lambda": {
				"Fn::Sub": “${postgresConnector}"
		}
		"cron": {
			"settings": {
				"source": “system:mysqlConnector",
				"destination": "LeadChanges",
				"slave": "system:postgresConnector"
			}
		},
		"time": "0 0 0 * * * "
	},

Step 6: Example index.js for the checksum bot:

const leo = require('leo-sdk');
const checksum = require('leo-connector-common/checksum');
const moment = require('moment');

exports.handler = function(event, context, callback) {
	let system = 'default';
	let db1 = checksum.lambdaConnector(‘MySQL DB Orders checksum', process.env.mysql_lambda, { // use the lambda name you specified in your package.json
		table: ‘orders',, // table name you want to compare
		id_column: ‘id',
		key_column: ‘primary’
		// fields: [‘id’, ‘status’] // the fields you would like to compare
	});

	let db2 = checksum.lambdaConnector('Postgres DW Orders checksum', process.env.postgres_lambda, { // use the lambda name you specified in your package.json
		table: 'd_orders’, // table name you want to compare
		id_column: 'id',
		key_column: ‘primary’,
		// fields: [‘id’, ‘status’] // the fields you would like to compare
	});

	checksum.checksum(system, event.botId, db1, db2, {
		stopOnStreak: 1750000, // The checksum will “complete” after it has searched through this many consecutive records with no differences.
		stop_at: moment().add({minutes: 4}), // default because of the 5-minute lambda run limit. The bot will run again, continuing where it left off.
		fieldNames: [ // unified labels for fields specified in the connectors above.
			‘id’, ‘Order Status’
		],
		limit: 20000, // starting limit of records to check simultaneously.
		maxLimit: 500000, // The upper limit of records to check simultaneously.
		loadSize: 50000, // The maximum number of records per event sent to the changes queue (specified by “queue” below).
		// shouldDelete: true, // delete records in the data warehouse if they no longer exist in the source/master database
		reverse: true, // reverse will start from the highest ID’s to the lowest
		sample: true, // return a sample of the ID’s incorrect/missing/extra
		queue: { // configuration for the queue to put the ID’s of the missing records into. You’ll usually want the same queue as the change tracking bot uses.
			name: event.destination, // queue name.
			transform: leo.streams.through((obj, done) => {
				done(null, {
					Lead: obj.missing.concat(obj.incorrect) // defines how this will be sent to the change queue. This must match what you’re already using in the change tracking bot, or are expecting from a transform bot.
				});
			})
		}
	})
	.then(data=>{ console.log(data); callback()})
	.catch(callback);
};

Now publish the bot and grab a pizza and root beer to watch the show!

